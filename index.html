<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Somesh Singh webpage">
    <meta name="author" content="Somesh">

    <title>Somesh Singh</title>

    <!-- Reseting CSS       -->
    <link href="css/normalize.css" rel="stylesheet">

    <!-- Bootstrap Core CSS -->
    <link href="css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom CSS -->
    <link href="css/mystylesheet.css" rel="stylesheet">

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

      <!-- Adding a favicon -->
<!--	<link rel="shortcut icon" href="img/favicon_IIT-M.png" type="image/x-icon" />
	<link rel="shortcut icon" href="img/favicon_s_blue.png" type="image/x-icon" /> -->
	<link rel="shortcut icon" href="img/favicon.ico" type="image/x-icon" />

</head>

<body>

    <!-- Navigation -->

    <div class="container">
	<h1 style="font-size:5rem; margin-bottom: 0.3em;">Somesh Singh</h1>
<!--
	<h4 style="margin-top: 0.3rem; margin-left: 0.5rem; margin-bottom:1em;">PhD Candidate,
	 <a href = "http://www.cse.iitm.ac.in/" target="_blank">CSE</a>,
	 <a href = "https://www.iitm.ac.in/" target="_blank">IITM</a>
	</h4>
-->
        <!-- /.container -->

       <!-- Page Content -->
    <div class="container">

        <div class="row">

	<div class="col-sm-3 col-lg-4">
	<img src="img/me.jpg"  class="img-responsive" alt="Somesh's pic">
        </div>
            <div class="col-sm-9 col-lg-8">
 <!--
                <h1>Starting with BootStrap</h1>
                <p class="lead"></p>
                <ul class="list-unstyled">
                    <li>Bootstrap v3.3.7</li>
                    <li>jQuery v1.11.1</li>
                </ul>
 -->
        <p>
<!--	Hello!
 I am a Ph.D. student in the department of
<a href="http://www.cse.iitm.ac.in/" target="_blank">
Computer Science and Engineering
</a>
at
<a href="http://www.iitm.ac.in/" target="_blank">
IIT Madras</a>.
I am advised by
<a href = "http://www.cse.iitm.ac.in/~rupesh/" target="_blank">Dr. Rupesh Nasre</a>.
My research focuses on designing techniques for accelerating large-scale graph analytics on -->
<!-- <em>large</em> graphs using -->
<!-- GPUs, aided by approximate computing.-->
I was a post-doctoral researcher
<!--
 with <a href="https://www.inria.fr/" target="_blank">INRIA</a>
-->
in the
<a href="http://www.ens-lyon.fr/LIP/ROMA/" target="_blank">ROMA</a>
team
at
<a href="http://www.ens-lyon.fr/LIP/" target="_blank">LIP</a>,
ENS de Lyon, where I was hosted by
<a href = "https://perso.ens-lyon.fr/bora.ucar/" target="_blank">Dr. Bora Uçar</a>.

Before that, I obtained my Ph.D. from the
<a href="http://www.cse.iitm.ac.in/" target="_blank">
Indian Institute of Technology Madras</a> under the supervision of
<!--I was advised by -->
<a href = "http://www.cse.iitm.ac.in/~rupesh/" target="_blank">Dr. Rupesh Nasre</a>.
        </p>
<!--
	 <p>
        I obtained my Bachelor's in Computer Science and Engineering from the
<a href = "http://nituk.ac.in/" target="_blank">National Institute of Technology Uttarakhand</a>.
        </p>
-->
	<hr />

	<h3>Contact:</h3>

	<p>
		<b>Somesh Singh</b><br/>
	<!--<a href = "http://pace.cse.iitm.ac.in/" target="_blank"> PACE Lab</a>,
	  BSB 331-A <br/>
	  Dept. of CSE<br/>
	  IIT Madras - 600 036.<br/> -->
	<!--
      Office: M7.306 <br/>
      LIP (UMR 5668 -- CNRS, Inria, ENS de Lyon, UCB Lyon 1) <br/>
      ENS de Lyon <br/>
      46, allée d'Italie <br/>
      69007 Lyon, France. <br/>
      <br/> -->
      <em>Email</em>: {firstname} (dot) {lastname}1992 (at) gmail (dot) com


    <!--
<ul>

<li>
    {firstname} (dot) {lastname}1992 (at) gmail (dot) com
</li>
   <br/>
<li>
   {firstname} (dot) {lastname} (at) ens-lyon (dot) fr
</li>

</ul>
-->

	</p>
<!--    <p>
	   <b>I am currently on the job market.</b> (expected graduation: July 2020)
	</p>  -->
        </div>


        </div>
        <!-- /.row -->
<hr />

        <div class="row">
<!--
	<div class="col-sm-3 col-lg-4">
	<img src="img/me.jpg"  class="img-responsive" alt="Somesh's pic">
        </div>
-->
            <div class="col-lg-12">
<h3 style="border-bottom: 1px solid black;padding-bottom:4px"> Research </h3>

<p>
<!--
My research interests span the broad areas of high-performance computing and parallel computing, with an emphasis on making the processing of irregular-workloads on parallel platforms more efficient.
-->
My research centers around high-performance parallel computing with an emphasis on sparse irregular computations.

The focus of my Ph.D. research was on accelerating parallel graph processing using approximate computing. Details about my Ph.D. dissertation can be found <a href="phddissertation.html">here</a>.

During postdoc, my focus was on designing and developing methods and techniques for high-performance sparse tensor computations.

<!--
Currently, my focus is on optimizing and enhancing the performance of sparse matrix and tensor computations on parallel architectures.
-->
</p>

<hr />

<p style="color:black">
<h3><u>Publications</u>
 <span style="position:relative; left: 2%; top: 4px">
<!--
<button type="button" class="btn btn-primary btn-sm" style="font-size:15px;">
 <a href="https://dblp.uni-trier.de/pers/hd/s/Singh_0001:Somesh" target="_blank" style="color:inherit">DBLP</a>
 </button>

 <button type="button" class="btn btn-primary btn-sm " style="font-size:15px;">
 <a href="https://scholar.google.co.in/citations?user=nwsoib8AAAAJ&hl=en&oi=ao" target="_blank" style="color:inherit">Google Scholar</a>
 </button>
-->
<a href="https://dblp.uni-trier.de/pid/226/7327-1.html" target="_blank" title="dblp"><i class="ai ai-dblp-square ai-1x"></i></a>
<a href="https://scholar.google.co.in/citations?user=nwsoib8AAAAJ" target="_blank" title="Google Scholar"><i class="ai ai-google-scholar-square ai-1x"></i></a>
 </span>
 </h3>

</p>

<b>*</b> : The authors are listed in alphabetical order by lastname.

<h3 style="font-size: 16pt">
Efficient Parallel Sparse Tensor Contraction*
</h3>
<h4 style="font-size: 13pt"><i>Somesh Singh,&#32;Bora U&#231;ar,</i></h4>
<h4 style="font-size: 13pt">as a Technical Report on HAL, 2024.</h4>
<p style="font-size: 11pt">
  <a data-toggle="collapse" href="#tr-hal" aria-expanded="false" aria-controls="tr-hal">
   (abstract)
  </a>

  <a href="https://hal.science/hal-04659658" target="_blank">(preprint)</a>
</p>

<p class="collapse" id="tr-hal" style="font-size: 11pt">
We investigate the performance of algorithms for sparse tensor-sparse tensor multiplication (SpGETT). This operation, also called sparse tensor contraction, is a higher order analogue of the sparse matrix-sparse matrix multiplication (SpGEMM) operation. Therefore, SpGETT can be performed by first converting the input tensors into matrices, then invoking high performance variants of SpGEMM, and finally reconverting the resultant matrix into a tensor. Alternatively, one can carry out the scalar operations underlying SpGETT in the realm of tensors without matrix formulation. We discuss the building blocks in both approaches and formulate a <em>hashing-based method</em> to avoid costly search or redirection operations. We present performance results with the current state-of-the-art SpGEMM-based approaches, existing SpGETT approaches, and a carefully implemented SpGETT approach with a new fine-tuned hashing method, proposed in this paper. We evaluate the methods on real world tensors by contracting a tensor with itself along varying dimensions. Our proposed hashing-based method for SpGETT consistently outperforms the state-of-the-art method, achieving a 25% reduction in sequential execution time on average and a 21% reduction in parallel execution time on average across a variety of input instances.
</p>


<h3 style="font-size: 16pt">
BANG: Billion-Scale Approximate Nearest Neighbour Search using a Single GPU
</h3>
<h4 style="font-size: 13pt"><i>Karthik V, Saim Khan, Somesh Singh, Harsha Vardhan Simhadri, Jyothi Vedurada,</i></h4>
<h4 style="font-size: 13pt">as arXiv preprint <em>arXiv:2401.11324</em>, 2024.</h4>
<p style="font-size: 11pt">
  <a data-toggle="collapse" href="#tbd24" aria-expanded="false" aria-controls="tbd24">
   (abstract)
  </a>

  <!-- <a href="docs/papers/arxiv24b.pdf" target="_blank">(pdf)</a> -->
  <a href="https://arxiv.org/abs/2401.11324" target="_blank">(preprint)</a>
  <a href="https://doi.org/10.48550/arXiv.2401.11324" target="_blank">(doi)</a>
</p>

<p class="collapse" id="tbd24" style="font-size: 11pt">
Approximate Nearest Neighbour Search (ANNS) is a subroutine in algorithms routinely employed in information retrieval, pattern recognition, data mining, image processing, and beyond. Recent works have established that graph-based ANNS algorithms are practically more efficient than the other methods proposed in the literature. The growing volume and dimensionality of data necessitates designing scalable techniques for ANNS. To this end, the prior art has explored parallelizing graph-based ANNS on GPU leveraging its massive parallelism. The current state-of-the-art GPU-based ANNS algorithms either (i) require both the dataset and the generated graph index to reside entirely in the GPU memory, or (ii) they partition the dataset into small independent shards, each of which can fit in GPU memory, and perform the search on these shards on the GPU. While the first approach fails to handle large datasets due to the limited memory available on the GPU, the latter delivers poor performance on large datasets due to high data traffic over the low-bandwidth PCIe bus. We introduce BANG, a first-of-its-kind technique for graph-based ANNS on GPU for billion-scale datasets that cannot entirely fit in the GPU memory. BANG stands out by harnessing a compressed form of the dataset on a single GPU to perform distance computations while efficiently accessing the graph index kept on the host memory, enabling efficient ANNS on large graphs within the limited GPU memory. BANG incorporates highly optimized GPU kernels and proceeds in phases that run concurrently on the GPU and CPU. Notably, on the billion-size datasets, we achieve throughputs 40&times;-200&times; more than the competing methods for a high recall value of 0.9. Additionally, BANG is the best in cost- and power-efficiency among the competing methods from the recent Billion-Scale Approximate Nearest Neighbour Search Challenge.
</p>


<h3 style="font-size: 16pt">
Engineering Fast Algorithms for the Bottleneck Matching Problem*
</h3>
<h4 style="font-size: 13pt"><i>Ioannis Panagiotas,&#32;Gr&eacute;goire Pichon,&#32;Somesh Singh,&#32;Bora U&#231;ar,</i></h4>
<h4 style="font-size: 13pt">in European Symposium on Algorithms (ESA), 2023.</h4>
<p style="font-size: 11pt">
  <a data-toggle="collapse" href="#esa23" aria-expanded="false" aria-controls="esa23">
   (abstract)
  </a>

  <a href="docs/papers/esa23.pdf" target="_blank">(pdf)</a>
  <a href="https://inria.hal.science/hal-04146298" target="_blank">(preprint)</a>
  <a href="https://doi.org/10.4230/LIPIcs.ESA.2023.87" target="_blank">(doi)</a>
  <a href="https://gitlab.inria.fr/bora-ucar/bottled" target="_blank">(code)</a>
</p>

<p class="collapse" id="esa23" style="font-size: 11pt">
We investigate the maximum bottleneck matching problem in bipartite graphs. Given a bipartite
graph with nonnegative edge weights, the problem is to determine a maximum cardinality matching
in which the minimum weight of an edge is the maximum. To the best of our knowledge, there are
two widely used solvers for this problem based on two different approaches. There exists a third
known approach in the literature, which seems inferior to those two which is presumably why there
is no implementation of it. We take this third approach, make theoretical observations to improve
its behavior, and implement the improved method. Experiments with the existing two solvers show
that their run time can be too high to be useful in many interesting cases. Furthermore, their
performance is not predictable, and slight perturbations of the input graph lead to considerable
changes in the run time. On the other hand, the proposed solver’s performance is much more stable;
it is almost always faster than or comparable to the two existing solvers, and its run time always
remains low.
</p>


<h3 style="font-size: 16pt">
Effective Parallelization of the Vehicle Routing Problem
</h3>
<h4 style="font-size: 13pt"><i>Rajesh Pandian M,&#32;Somesh Singh,&#32;Rupesh Nasre,&#32;N.S. Narayanaswamy,</i></h4>
<h4 style="font-size: 13pt">in Genetic and Evolutionary Computation Conference (GECCO), 2023.</h4>
<p style="font-size: 11pt">
  <a data-toggle="collapse" href="#gecco23" aria-expanded="false" aria-controls="gecco23">
   (abstract)
  </a>

  <a href="docs/papers/gecco23.pdf" target="_blank">(pdf)</a>
  <a href="https://doi.org/10.1145/3583131.3590458" target="_blank">(doi)</a>
</p>

<p class="collapse" id="gecco23" style="font-size: 11pt">
Capacitated Vehicle Routing Problem (CVRP) is an important combinatorial optimization problem, which is also NP-hard. A wide array
of heuristics have been proposed in the literature to obtain an approximate solution to CVRP. To improve the execution time, parallel
methods have been developed for accelerating metaheuristics-based algorithms, genetic algorithms, and evolutionary algorithms for
CVRP. Despite these advances, our experiments with the state-of-the-art parallel solutions indicate that their run times are too high
to be practically useful. The combinatorial explosion is so high that the execution time is prohibitively large even on mid-sized CVRP instances having a few hundred customers.
In this work, we propose a novel technique which combines <em>local search</em> and <em>randomization</em> for solving CVRP faster with reasonable accuracy, even on large
problem instances. Our usage of randomization enables searching a large space of candidate solutions.
We experimentally compare our proposed method with the state-of-the-art GPU implementations on diverse input instances and demonstrate the efficacy of our
approach. Our sequential and shared-memory parallel implementations are on an average 36&times;-1189&times; faster than the state-of-the-art GPU-parallel genetic algorithms while also achieving a superior
solution quality. Furthermore, our reported solutions are close to the current best-known solutions from CVRPLIB.
</p>



<h3 style="font-size: 16pt">
Algorithms and Data Structures for Hyperedge Queries*
</h3>
<h4 style="font-size: 13pt"><i>Jules Bertrand,&#32;Fanny Dufoss&eacute;,&#32;Somesh Singh,&#32;Bora U&#231;ar,</i></h4>
<h4 style="font-size: 13pt">in ACM Journal of Experimental Algorithmics (JEA), 2022.</h4>
<p style="font-size: 11pt">
  <a data-toggle="collapse" href="#jea22" aria-expanded="false" aria-controls="jea22">
   (abstract)
  </a>

  <a href="docs/papers/jea22.pdf" target="_blank">(pdf)</a>
  <a href="https://hal.inria.fr/hal-03905905" target="_blank">(preprint)</a>
  <a href="https://doi.org/10.1145/3568421" target="_blank">(doi)</a>
  <a href="https://gitlab.inria.fr/bora-ucar/hedge-queries" target="_blank">(code)</a>
    <a href="https://www.acm.org/publications/policies/artifact-review-and-badging-current#reproduced" target="_blank">
<span style="color: #23007d; font-weight:bold;">[ACM Results Reproduced Badge]</span>
  <img src="img/acm_results_reproduced_v1_1.png" alt="" width="32" height="32" border="0">
    </a>
</p>

<p class="collapse" id="jea22" style="font-size: 11pt">
We consider the problem of querying the existence of hyperedges in hypergraphs. More formally, given a hypergraph, we need to answer queries of the form: "Does the following set of vertices form a hyperedge in the given hypergraph?" Our aim is to set up data structures based on hashing to answer these queries as fast as possible. We propose an adaptation of a well-known perfect hashing approach for the problem at hand. We analyze the space and runtime complexity of the proposed approach and experimentally compare it with the state-of-the-art hashing-based solutions. Experiments demonstrate the efficiency of the proposed approach with respect to the state-of-the-art.
</p>

<h3 style="font-size: 16pt">
An Efficient Parallel Implementation of a Perfect Hashing Method for Hypergraphs*
</h3>
<h4 style="font-size: 13pt"><i>Somesh Singh,&#32;Bora U&#231;ar,</i></h4>
<h4 style="font-size: 13pt">in GrAPL: Workshop on Graphs, Architectures, Programming, and Learning, IPDPSW 2022. </h4>
<p style="font-size: 11pt">
  <a data-toggle="collapse" href="#grapl22" aria-expanded="false" aria-controls="grapl22">
   (abstract)
  </a>

  <a href="docs/papers/grapl22.pdf" target="_blank">(pdf)</a>
  <a href="https://hal.inria.fr/hal-03612360" target="_blank">(preprint)</a>
  <a href="https://doi.org/10.1109/IPDPSW55747.2022.00056" target="_blank">(doi)</a>
</p>

<p class="collapse" id="grapl22" style="font-size: 11pt">
Querying the existence of an edge in a given graph or hypergraph is a building block in several algorithms.
Hashing-based methods can be used for this purpose, where the given edges are stored in a hash table in a preprocessing step, and then the queries are answered using the lookup operations.
While the general hashing methods have fast lookup times in the average case, the worst case run time is much higher.
Perfect hashing methods take advantage of the fact that the items to be stored are all available and construct a collision free hash function for the given input, resulting in an optimal lookup time
even in the worst case.
We investigate an efficient shared-memory parallel implementation of a recently proposed perfect hashing method for hypergraphs.
We experimentally compare the resulting parallel algorithms with the state-of-the-art and demonstrate better run time and scalability on a set of hypergraphs corresponding to real-life sparse tensors.
</p>


<h3 style="font-size: 16pt">
ParTBC: Faster Estimation of Top-<em>k</em> Betweenness Centrality Vertices on GPU
</h3>
<h4 style="font-size: 13pt"><i>Somesh Singh,&#32;Tejas Shah,&#32;Rupesh Nasre,</i></h4>
<h4 style="font-size: 13pt">in ACM Transactions on Design Automation of Electronic Systems (TODAES), 2021. </h4>
<p style="font-size: 11pt">
  <a data-toggle="collapse" href="#todaes21" aria-expanded="false" aria-controls="todaes21">
   (abstract)
  </a>

  <a href="docs/papers/todaes21.pdf" target="_blank">(pdf)</a>
  <a href="https://doi.org/10.1145/3486613" target="_blank">(doi)</a>
</p>

<p class="collapse" id="todaes21" style="font-size: 11pt">
Betweenness centrality (BC) is a popular centrality measure, based on shortest paths, used to quantify the importance of vertices in networks. It is used in a wide array of applications including social network analysis, community detection, clustering, biological network analysis, and several others. The state-of-the-art Brandes' algorithm for computing BC has time complexities of <span style="font-size: 13pt"><b>&#x1D4DE;</b></span>( |V|&#183;|E| ) and <span style="font-size: 13pt"><b>&#x1D4DE;</b></span>( |V|&#183;|E| + |V|<sup>2</sup>&#183;log|V| ) for unweighted and weighted graphs, respectively. Brandes' algorithm has been successfully parallelized on multicore and manycore platforms. However, the computation of vertex BC continues to be time-consuming for large real-world graphs. Often, in practical applications, it suffices to identify the most important vertices in a network; that is, those having the highest BC values. Such applications demand only the top vertices in the network as per their BC values but do not demand their actual BC values. In such scenarios, not only
is computing the BC of all the vertices unnecessary but also exact BC values need not be computed. In this work, we attempt to marry controlled approximations with parallelization to estimate the k-highest BC vertices faster, without having to compute the exact BC scores of the vertices. We present a host of techniques to determine the top-k vertices faster, with a small inaccuracy, by computing approximate BC scores of the vertices. Aiding our techniques is a novel vertex-renumbering scheme to make the graph layout more structured, which results in faster execution of parallel Brandes' algorithm on GPU. Our experimental results, on a suite of real-world and synthetic graphs, show that our best performing technique computes the top-k vertices with an average speedup of 2.5&times; compared to the exact parallel Brandes' algorithm on GPU, with an error of less than 6%. Our techniques also exhibit high precision and recall, both in excess of 94%.
</p>

<h3 style="font-size: 16pt">
Graffix: Efficient Graph Processing with a Tinge of GPU-Specific Approximations
</h3>
<h4 style="font-size: 13pt"><i>Somesh Singh,&#32;Rupesh Nasre,</i></h4>
<h4 style="font-size: 13pt">in International Conference on Parallel Processing (ICPP), 2020. </h4>
<p style="font-size: 11pt">
  <a data-toggle="collapse" href="#icpp20" aria-expanded="false" aria-controls="icpp20">
   (abstract)
  </a>

  <a href="docs/papers/icpp20.pdf" target="_blank">(pdf)</a>
  <a href="https://doi.org/10.1145/3404397.3404406" target="_blank">(doi)</a>
  <a href="https://www.youtube.com/watch?v=KwydMszR5Bg" target="_blank">(talk)</a>
</p>

<p class="collapse" id="icpp20" style="font-size: 11pt">
Parallelizing graph algorithms on GPUs is challenging due to the irregular memory accesses involved in graph traversals. In particular,
three important GPU-specific aspects affect performance: memory coalescing, memory latency, and thread divergence. In this work,
we attempt to tame these challenges using approximate computing. We target graph applications on GPUs that can tolerate some degradation in the quality of the output, for obtaining the result in short order. We propose three techniques for boosting the performance
of graph processing on the GPU by injecting approximations in a controlled manner. The first one creates a graph isomorph that
brings relevant nodes nearby in memory and adds controlled replica of nodes to improve coalescing. The second reduces memory latency by facilitating the processing of subgraphs inside shared memory by adding edges among specific nodes and processing
well-connected subgraphs iteratively inside shared memory. The third technique normalizes degrees across nodes assigned to a warp
to reduce thread divergence. Each of the techniques offers notable performance benefits, and provides a knob to control the amount of
inaccuracy added to an execution. We demonstrate the effectiveness of the proposed techniques using a suite of five large graphs with
varied characteristics and five popular graph algorithms.
</p>

<h3 style="font-size: 16pt">
 SixTrack V and runtime environment
 </h3>
 <h4 style="font-size: 13pt"><font color="#696969">with</font> <i> R. De Maria, J. Andersson, V.K. Berglyd Olsen, L. Field, M. Giovannozzi, P.D. Hermes, N. H&#248imyr,
 S. Kostoglou, G. Iadarola, E. Mcintosh, A. Mereghetti, J. Molson, D. Pellegrini,
 T. Persson, M. Schwinzerl, E.H. Maclean, K.N. Sjobak, I. Zacharov, </i> <!-- <i>et al.</i>  --> </h4>
 <h4 style="font-size: 13pt">in International Journal of Modern Physics A, 2019. (Invited Paper)</h4>
 <p style="font-size: 11pt">
   <a data-toggle="collapse" href="#ijmpa" aria-expanded="false" aria-controls="ijmpa">
    (abstract)
   </a>

   <a href="docs/papers/ijmpa19.pdf" target="_blank">(pdf)</a>
   <a href="https://doi.org/10.1142/S0217751X19420351" target="_blank">(doi)</a>
 </p>

 <p class="collapse" id="ijmpa" style="font-size: 11pt">
SixTrack is a single-particle tracking code for high-energy circular accelerators routinely used at CERN for the Large Hadron Collider (LHC), its luminosity upgrade (HL-LHC), the Future Circular Collider (FCC) and the Super Proton Synchrotron (SPS) simulations.
The code is based on a 6D symplectic tracking engine, which is optimized for long-term tracking simulations and delivers fully reproducible results on several platforms.
It also includes multiple scattering engines for beam–matter interaction studies, as well as facilities to run the integrated simulations with external particle matter interaction codes.
These features differentiate SixTrack from general-purpose, optics-design software.
The code recently underwent a major restructuring to merge the advanced features into a single branch, such as multiple ion species, interface with external codes and high-performance input/output.
This restructuring also removed a large number of compilation flags, instead enabling/disabling the functionality with runtime options.
In the process, the code was moved from Fortran 77 to Fortran 2018 standard, also allowing and achieving a better modularization.
Physics models (beam–beam effects, Radio-Frequency (RF) multipoles, current carrying wires, solenoid and electron lenses) and methods (symplecticity check) have also been reviewed and refined to offer more accurate results.
The SixDesk runtime environment allows the user to manage the large batches of simulations required for accurate predictions of the dynamic aperture. SixDesk supports several cluster environments available at CERN as well as submitting jobs to the LHC@Home volunteering computing project, which enables volunteers contributing with their hardware to CERN simulation.
SixTrackLib is a new library aimed at providing a portable and flexible tracking engine for single- and multi-particle problems using the models and formalism of SixTrack. The library is able to run in CPUs as well as graphical processing units (GPUs).
This contribution presents the status of the code, summarizes the main existing features and provides details about the main development lines SixTrack, SixDesk and SixTrackLib.
 </p>

<h3 style="font-size: 16pt">
Optimizing Graph Processing on GPUs using Approximate Computing: Poster
</h3>
<h4 style="font-size: 13pt"><i>Somesh Singh,&#32;Rupesh Nasre,</i></h4>
<h4 style="font-size: 13pt">in ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming (PPoPP), 2019.</h4>
<p style="font-size: 11pt">
  <a data-toggle="collapse" href="#ppopp19" aria-expanded="false" aria-controls="ppopp19">
   (abstract)
  </a>

  <a href="docs/papers/ppopp19.pdf" target="_blank">(pdf)</a>
  <a href="https://doi.org/10.1145/3293883.3295736" target="_blank">(doi)</a>
</p>

<p class="collapse" id="ppopp19" style="font-size: 11pt">
Parallelizing graph algorithms on GPUs is challenging due to the irregular memory accesses and control-flow involved in
graph traversals. In this work, we tame these challenges by injecting approximations. In particular, we improve memory
coalescing by renumbering and replicating nodes, memory latency by adding edges among specific nodes brought into
shared memory, and thread-divergence by normalizing degrees across nodes assigned to a warp. Using a suite of graphs
with varied characteristics and five popular algorithms, we demonstrate the effectiveness of our proposed techniques.
Our approximations for coalescing, memory latency and thread-divergence lead to mean speedups of 1.3&times;, 1.41&times; and 1.06&times; achieving accuracies of 83&percnt;, 78&percnt; and 84&percnt;, respectively.
</p>

<h3 style="font-size: 16pt">
 SixTrack Project: Status, Runtime Environment, and New Developments
 </h3>
 <h4 style="font-size: 13pt"><font color="#696969">with</font> <i> R. De Maria, J. Andersson, V.K. Berglyd Olsen, L. Field, M. Giovannozzi, P.D. Hermes, N. H&#248imyr,
 S. Kostoglou, G. Iadarola, E. Mcintosh, A. Mereghetti, J. Molson, D. Pellegrini,
 T. Persson, M. Schwinzerl, E.H. Maclean, K.N. Sjobak, I. Zacharov, </i> <!-- <i>et al.</i>  --> </h4>
 <h4 style="font-size: 13pt">in International Computational Accelerator Physics Conference (ICAP), 2018.</h4>
 <p style="font-size: 11pt">
   <a data-toggle="collapse" href="#icap" aria-expanded="false" aria-controls="icap">
    (abstract)
   </a>

   <a href="docs/papers/icap18.pdf" target="_blank">(pdf)</a>
   <a href="https://doi.org/10.18429/JACoW-ICAP2018-TUPAF02" target="_blank">(doi)</a>
 </p>

 <p class="collapse" id="icap" style="font-size: 11pt">
SixTrack is a single-particle tracking code for high-energy circular accelerators routinely used at CERN for the Large Hadron Collider (LHC), its luminosity upgrade (HL-LHC), the Future Circular Collider (FCC), and the Super Proton Synchrotron (SPS) simulations.
The code is based on a 6D symplectic tracking engine, which is optimised for long-term tracking simulations and delivers fully reproducible results on several platforms.
It also includes multiple scattering engines for beam-matter interaction studies, as well as facilities to run integrated simulations with FLUKA and GEANT4.
These features differentiate SixTrack from general-purpose, optics-design software like MAD-X.
The code recently underwent a major restructuring to merge advanced features into a single branch, such as multiple ion species, interface with external codes, and high-performance input/output (XRootD, HDF5).
This restructuring also removed a large number of build flags, instead enabling/disabling the functionality at run-time.
In the process, the code was moved from Fortran 77 to Fortran 2018 standard, also allowing and achieving a better modularization.
Physics models (beam-beam effects, RF-multipoles, current carrying wires, solenoid, and electron lenses) and methods (symplecticity check) have also been reviewed and refined to offer more accurate results.
The SixDesk runtime environment allows the user to manage the large batches of simulations required for accurate predictions of the dynamic aperture.
SixDesk supports CERN LSF and HTCondor batch systems, as well as the BOINC infrastructure in the framework of the LHC@Home volunteering computing project.
SixTrackLib is a new library aimed at providing a portable and flexible tracking engine for single- and multi-particle problems using the models and formalism of SixTrack.
The tracking routines are implemented in a parametrized C code that is specialised to run vectorized in CPUs and GPUs, by using SIMD intrinsics, OpenCL 1.2, and CUDA technologies.
This contribution presents the status of the code and an outlook on future developments of SixTrack, SixDesk, and SixTrackLib.
 </p>


<h3 style="font-size: 16pt">
Scalable and Performant Graph Processing on GPUs using Approximate Computing
</h3>
<h4 style="font-size: 13pt"><i>Somesh Singh,&#32;Rupesh Nasre,</i></h4>
<h4 style="font-size: 13pt">in IEEE Transactions on Multi-Scale Computing Systems (TMSCS), 2018. </h4>
<p style="font-size: 11pt">
  <a data-toggle="collapse" href="#tmscs" aria-expanded="false" aria-controls="tmscs">
   (abstract)
  </a>

  <a href="docs/papers/tmscs.pdf" target="_blank">(pdf)</a>
  <a href="https://doi.org/10.1109/TMSCS.2018.2795543" target="_blank">(doi)</a>
</p>
<p class="collapse" id="tmscs" style="font-size: 11pt">
Graph algorithms are widely used in several application domains. It has been established that parallelizing graph
algorithms is challenging. The parallelization issues get exacerbated when graphics processing units (GPUs) are used to execute
graph algorithms. While the prior art has shown effective parallelization of several graph algorithms on GPUs, a few algorithms are still
expensive. In this work, we address the scalability issues in graph parallelization. In particular, we aim to improve the execution time by
tolerating a little approximation in the computation. We study the effects of four heuristic approximations on six graph algorithms with
five graphs and show that if an application allows for small inaccuracy, this can be leveraged to achieve considerable performance
benefits. We also study the effects of the approximations on GPU-based processing and provide interesting takeaways.
</p>

<hr />

<p style="color:black">
<h3><u>Patents</u></h3>
</p>

<h3 style="font-size: 16pt">
Method and System for Performing Approximate Nearest Neighbour Search on Billion-Scale Vectors
</h3>
<h4 style="font-size: 13pt"><i>Karthik V, Somesh Singh, Harsha Vardhan Simhadri, Jyothi Vedurada,</i></h4>
<h4 style="font-size: 13pt">Indian Patent, filed 2024. (Patent Pending)</h4>

<hr />

<h3 style="border-bottom: 1px solid black;padding-bottom:4px"> Other Projects </h3>
</br>

<div style="font-size:18px;">
<ul>

<li>
<dl>
  Awarded
  $1000 in
  <a href= "https://edu.google.com/programs/?modal_active=none" target="_blank">
     Google Cloud Platform</a>
  credits for research on <em>parallel subgraph isomorphism</em>
  <span style="float:right;font-weight:normal; font-style:italic">
    2020
  </span>
</dl>
</li>

<li>
 <dl>
      Google Summer of Code 2018 : <a href= "https://summerofcode.withgoogle.com/archive/2018/projects/5152248673861632/" target="_blank">
      <em>Optimize and Integrate Standalone Tracking Library (SixTrackLib)
 </em></a>
 <span style="float:right;font-weight:normal; font-style:italic">
 <a href= "http://hepsoftwarefoundation.org/activities/gsoc.html" target="_blank"><em>SixTrack, CERN-HSF</em> </a>
 </span>
 <p style="font-size:16px; display:list-item; list-style-type: circle; list-style-position:inside;">  <!-- color:#00A598"-->
 Developed a standalone parallel implementation of (a part of) SixTrackLib.
 The contributed code is available
 <a href="https://github.com/ssomesh/sixtracklib_gsoc18/tree/master/" target="_blank">
     here</a>.
 </p>
 </dl>
 </li>



<li>
<dl>
        Google Summer of Code 2017 : <a href= "https://summerofcode.withgoogle.com/archive/2017/projects/6549039684255744/" target="_blank">
        <em>Smart Data Structures in CUDA</em> </a>
<span style="float:right;font-weight:normal; font-style:italic">
<a href= "http://hepsoftwarefoundation.org/activities/gsoc.html" target="_blank">
       <em>CMS, CERN-HSF</em> </a>
</span>
<p style="font-size:16px; display:list-item; list-style-type: circle; list-style-position:inside;">
 Developed
<a href= "https://github.com/ssomesh/SALLOC/tree/master" target="_blank">
        <em>SALLOC</em> </a>
-- An arena based memory allocator for SIMT architectures.
 </p>
</dl>
</li>

</div>




        </div>


        </div>
        <!-- /.row -->
<hr />

        <div class="row">
<!--
	<div class="col-sm-3 col-lg-4">
	<img src="img/me.jpg"  class="img-responsive" alt="Somesh's pic">
        </div>
-->
            <div class="col-lg-12">
<h3 style="border-bottom: 1px solid black;padding-bottom:4px"> Miscellaneous </h3>

<!--<h3>Accomplishments and Awards</h3> -->
<h3>Accomplishments</h3>
<!-- Pic saying page is under construction-->
<!--
     <p style="text-align:center; "><img style="max-width: 50%; margin-top: 1rem;" src="./img/construction.gif" alt="under_construction" border="2" /></p>
-->
<div style="font-size:18px;">
<ul>

<li>
<dl>
  <a href="docs/certificates/Certificate_HLF_SinghSomesh.pdf" target="_blank">
  Selected</a>
  for attending the
  <a href= "https://www.heidelberg-laureate-forum.org/" target="_blank">
      Heidelberg Laureate Forum</a>.
       <span style="float:right; font-weight:normal; font-style: italic;"> September 2020 </span>
</dl>
</li>

<li>
<dl>
  Awarded <em>ACM SIGPLAN PAC</em> grant for attending
  <a href= "https://ppopp19.sigplan.org/" target="_blank">PPoPP 2019</a>.
</dl>
</li>


<li>
<dl>
    <em>STAR TA Award</em> for contributions as a Teaching Assistant to "GPU Programming" course.
       <span style="float:right; font-weight:normal; font-style: italic;"> November 2017 </span>
</dl>
</li>


<li>
<dl>
        Secured <b>4th place</b> in HiPC 2016 Student Parallel Programming Challenge (Intel track).
</dl>
</li>

<li>
<dl>
        Secured <b>4th place</b>  in HiPC 2015 Student Parallel Programming Challenge (Intel track).
</dl>
</li>

</div>

</hr>

<h3>Professional Service</h3>
<!-- Pic saying page is under construction-->
<!--
     <p style="text-align:center; "><img style="max-width: 50%; margin-top: 1rem;" src="./img/construction.gif" alt="under_construction" border="2" /></p>
-->
<div style="font-size:18px;">
<ul>

<li>
<dl>
    Reviewer:

  <a href= "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=71" target="_blank">
	  IEEE Transactions on Parallel and Distributed Systems</a> (since 2021),

  <a href= "https://dl.acm.org/journal/taco" target="_blank">
	  ACM Transactions on Architecture and Code Optimization</a> (since 2022),

  <a href= "https://www.journals.elsevier.com/parallel-computing" target="_blank">
	  Parallel Computing</a> (since 2021)
  [<a href="docs/certificates/Certificate_PARCO_Recognised.pdf" target="_blank">certificate</a>],

  <a href= "https://onlinelibrary.wiley.com/journal/15320634" target="_blank">
	  Concurrency and Computation: Practice and Experience</a> (since 2021)
  [<a href="docs/certificates/CPE_Reviewer_Certificate_2021.pdf" target="_blank">certificate</a>],


  <a href= "https://www.sciencedirect.com/journal/computer-physics-communications" target="_blank">
	  Computer Physics Communications</a> (since 2023),

  <a href= "https://www.springer.com/journal/41403" target="_blank">
      Transactions of the Indian National Academy of Engineering</a> (since 2018),

  <a href= "https://ieeexplore.ieee.org/xpl/aboutJournal.jsp?punumber=4563995" target="_blank">
	 IEEE Embedded Systems Letters</a> (since 2017).

</dl>
</li>

<li>
<dl>
    Program Committee:

  <a href= "https://hpc.pnl.gov/grapl/previous/2023/" target="_blank">
       GrAPL 2023</a> (IPDPSW).

</dl>
</li>

<li>
<dl>
    Extended Review Committee:

  <a href= "https://2023.ecoop.org/committee/ecoop-2023-research-papers-extended-review-committee" target="_blank">
       ECOOP 2023</a>,

  <a href= "https://2022.ecoop.org/committee/ecoop-2022-papers-extended-review-committee-" target="_blank">
       ECOOP 2022</a>.


</dl>
</li>

<li>
<dl>
    Subreviewer:

  <a href= "https://sc24.supercomputing.org/" target="_blank">
       SC 2024</a>,

  <a href= "https://2022.hipc.org/" target="_blank">
       HiPC 2022</a>.

</dl>
</li>

<li>
<dl>
    Artifact Evaluation Committee:

  <a href= "https://2025.splashcon.org/committee/splash-2025-oopsla-artifacts-artifact-evaluation-committee" target="_blank">
        OOPSLA 2025</a>,

  <a href= "https://pldi24.sigplan.org/committee/pldi-2024-pldi-research-artifacts-artifact-evaluation-committee" target="_blank">
        PLDI 2024</a>,

  <a href= "https://etaps.org/2023/conferences/artifact-evaluation-esop-fossacs/" target="_blank">
        ESOP and FoSSaCS 2023</a>,

  <a href= "https://2023.ecoop.org/committee/ecoop-2023-artifact-evaluation-artifact-evaluation-committee" target="_blank">
        ECOOP 2023</a>,

  <a href= "https://conf.researchr.org/committee/issta-2022/issta-2022-artifact-evaluation-artifact-evaluation-committee" target="_blank">
        ISSTA 2022</a>,

  <a href= "https://pldi22.sigplan.org/committee/pldi-2022-PLDI-Research-Artifacts-artifact-evaluation-committee" target="_blank">
        PLDI 2022</a>,

     <a href= "https://etaps.org/user-profile/archive/53-etaps-2022/491-esop-2022-artifact-evaluation.html" target="_blank">
        ESOP 2022</a>,

  <a href= "https://2022.ecoop.org/committee/ecoop-2022-artifacts-artifact-evaluation-committee" target="_blank">
        ECOOP 2022</a>,

  <a href= "https://2021.ecoop.org/committee/ecoop-2021-ecoop-artifacts-artifact-evaluation-committee" target="_blank">
        ECOOP 2021</a>,

  <a href= "https://ppopp21.sigplan.org/committee/PPoPP-2021-artifact-evaluation-committee" target="_blank">
        PPoPP 2021</a>,

  <a href= "https://2020.ecoop.org/committee/ecoop-2020-artifacts-artifact-evaluation-committee" target="_blank">
        ECOOP 2020</a>,

  <a href= "https://ppopp18.sigplan.org/committee/ppopp-2018-artifact-evaluation-committee" target="_blank">
        PPoPP 2018</a>.
</dl>
</li>

<li>
<dl>
     Student Volunteer (SV) for
  <a href= "https://2020.splashcon.org/" target="_blank">
       SPLASH</a>
     /
  <a href= "https://2020.ecoop.org/" target="_blank">
       ECOOP 2020</a>.

</dl>
</li>

<li>
<dl>
    Organizer for <em>CUDA Workshop</em> in <em>Exebit 2018</em> at IIT Madras.
</dl>
</li>

</ul>


</div>

</hr>

<h3> Selected Invited Talks </h3>

<div style="font-size:18px;">
<ul>

<li>
<dl>
  <a href= "https://topal.gitlabpages.inria.fr/topal-working-group/" target="_blank">
       Talks</a>
 at
<a href="https://topal.gitlabpages.inria.fr/" target="_blank">TOPAL Inria Team</a>, Bordeaux, France.

  <span style="float:right;font-weight:normal; font-style:italic">
    March 2024 &amp; December 2023 
  </span>
</dl>
</li>

<li>
<dl>
  <a href= "https://app.swapcard.com/event/isc-high-performance-2023/planning/UGxhbm5pbmdfMTIyMDgxNg==" target="_blank">
       Talk</a>
 at the
 <i>Focus Session on High Performance Tensor Computations</i>
 at
<a href="https://www.isc-hpc.com/" target="_blank">
ISC 2023</a>, Hamburg, Germany.

  <span style="float:right;font-weight:normal; font-style:italic">
    May 2023
  </span>
</dl>
</li>

<li>
<dl>
  <a href= "https://meetings.siam.org/sess/dsp_talk.cfm?p=125348" target="_blank">
       Talk</a>
  at the
  <i>minisymposium on Recent Advances in Combinatorial Scientific Computing </i>
 at
<a href="https://www.siam.org/conferences/cm/conference/cse23" target="_blank">
SIAM CSE'23</a>, Amsterdam, The Netherlands.

  <span style="float:right;font-weight:normal; font-style:italic">
    February 2023
  </span>
</dl>
</li>

<li>
<dl>
  <a href= "https://sparsedays.cerfacs.fr/en/slides-2022/" target="_blank">
       Talk</a>
 at
<a href="https://sparsedays.cerfacs.fr/en/sparse-days-meeting-2022-in-saint-girons-iv/" target="_blank">
Sparse Days 2022</a>, Saint-Girons, France.

  <span style="float:right;font-weight:normal; font-style:italic">
    June 2022
  </span>
</dl>
</li>

<li>
<dl>
  <a href= "https://scheduling2022.sciencesconf.org/program" target="_blank">
       Talk</a>
 at
<a href="https://scheduling2022.sciencesconf.org/" target="_blank">
15th Scheduling for Large Scale Systems Workshop</a>, Fr&#233;jus, France.

  <span style="float:right;font-weight:normal; font-style:italic">
    June 2022
  </span>
</dl>
</li>

<li>
<dl>
  <a href= "http://www.ens-lyon.fr/LIP/ROMA/workinggroup.php" target="_blank">
       Talk</a>
 at
<a href="https://www.ens-lyon.fr/LIP/ROMA/" target="_blank">ROMA Inria Team</a>
 at
<a href="http://www.ens-lyon.fr/LIP/" target="_blank">LIP</a>, Lyon, France.

  <span style="float:right;font-weight:normal; font-style:italic">
    March 2022
  </span>
</dl>
</li>

<li>
<dl>
[Virtual]
  <a href= "https://meetings.siam.org/sess/dsp_talk.cfm?p=119071" target="_blank">
       Talk</a>
  at the
  <i>minisymposium on Parallel Processing in Data Science Applications</i>
 at
  <a href= "https://www.siam.org/conferences/cm/conference/pp22" target="_blank">
       SIAM PP'22</a>.

  <span style="float:right;font-weight:normal; font-style:italic">
    February 2022
  </span>
</dl>
</li>

<li>
<dl>
[Virtual]
  <a href= "https://www.ics.forth.gr/lecture/15243" target="_blank">
       Talk</a>
 at
  <a href= "https://www.ics.forth.gr" target="_blank">
       FORTH-ICS</a>.

  <span style="float:right;font-weight:normal; font-style:italic">
    July 2021
  </span>
</dl>
</li>

<li>
<dl>
[Virtual]
  <a href= "https://blogs.qub.ac.uk/DIPSA/efficient-parallel-graph-processing-on-gpu-using-approximate-computing-by-somesh-singh/" target="_blank">
       Talk</a>
 at
  <a href= "https://www.qub.ac.uk/schools/eeecs/" target="_blank">
  Queen’s University Belfast</a>.

  <span style="float:right;font-weight:normal; font-style:italic">
    May 2021
  </span>
</dl>
</li>

<li>
<dl>
[Virtual]
  <!--<a href= "https://stratcomm-elements.lbl.gov/berkeley-lab-events-calendar/" target="_blank">-->
  <a href= "https://crd.lbl.gov/resources/computing-sciences-seminars/" target="_blank">
       Talk</a>
 at
  <a href= "https://crd.lbl.gov/" target="_blank">
Lawrence Berkeley National Laboratory</a>.
  <span style="float:right;font-weight:normal; font-style:italic">
    March 2021
  </span>
</dl>
</li>


</ul>

</div>

        </div>


        </div>
        <!-- /.row -->


<hr />

        <div class="row">
<!--
	<div class="col-sm-3 col-lg-4">
	<img src="img/me.jpg"  class="img-responsive" alt="Somesh's pic"> 
        </div>
-->
            <div class="col-lg-12">
<h3 style="border-bottom: 1px solid black;padding-bottom:4px"> Mentoring </h3>
<!-- Pic saying page is under construction-->

<!--
     <p style="text-align:center; "><img style="max-width: 50%; margin-top: 1rem;" src="./img/construction.gif" alt="under_construction" border="2" /></p> 
-->

 <h3>Events</h3>
 <div style="font-size:16px;">
 <ul>
 <li>
 <dl>
   <dt> 
      <a href = "https://www.gpuhackathons.org/event/c-dac-hpc-hackathon-2021" target="_blank">C-DAC HPC Hackathon 2021</a>
        <span style="float:right;font-weight:normal; font-style: italic;"> July-August 2021  </span>    
   </dt>
<!--
   <dd style="color:#C4820E;">
       Approximate Betweenness Centrality
   </dd>   
-->
 </dl> 
 </li>
 </ul>
 </div>

 <h3>M.Tech Project</h3>
 <div style="font-size:16px;">
 <ul>
 <li>
 <dl>
   <dt> 
      Tejas Shah<span style="font-weight:normal;">,
   <a href = "https://www.iitm.ac.in/" target="_blank">IIT Madras</a>, Chennai </span> 
        <span style="float:right;font-weight:normal; font-style: italic;"> 2017-18  </span>    
   </dt>
   <dd style="color:#C4820E;">
       Approximate Betweenness Centrality
   </dd>   
 </dl> 
 </li>
 </ul>
 </div>

<h3> Interns </h3>
<div style="font-size:16px;">
<ul>
<li>
<dl>
  <dt> 
     Milind Srivastava<span style="font-weight:normal;">, 
	<a href = "https://www.iitm.ac.in/" target="_blank">IIT Madras</a>, Chennai </span> 
       <span style="float:right;font-weight:normal; font-style: italic;">December 2016 </span>
  </dt>
  <dd>  
      <a href="docs/code/MilindSrivastava-ImageSegmentation.tar.gz" download style="color:#C4820E;"> 
      Graph-based Image Segmentation </a> 
  </dd>
</dl>
</li>
<li>
<dl>
  <dt> Ronak Jayesh Shukla<span style="font-weight:normal;">, 
	<a href = "https://vnit.ac.in/" target="_blank"> VNIT</a>, Nagpur </span>
       <span style="float:right; font-weight:normal; font-style: italic;">June 2015 </span>
 </dt>
  <dd> 
      <a href="docs/code/RonakShukla-ObjectTrackingSegmentation.tar.gz" download style="color:#C4820E;"> 
      Image Segmentation and Object Tracking on GPU </a>
 </dd>
</dl>
</li>
</div>
           </div>

        </div>
        <!-- /.row -->
<hr />

<div>

<span style="float:right">

    <a href="https://github.com/ssomesh/" target="_blank">
     <img
          src="img/github.png"
          alt="View Somesh Singh's GitHub Repository" width="32" height="32" style="padding: 5px;" border="0">
    </a>

    <a href="https://www.linkedin.com/in/somesh-singh-17aab053" target="_blank">
     <img
          src="img/linkedin_2000px.svg.png"
          alt="View Somesh Singh's profile on LinkedIn" width="32" height="32" style="padding: 5px;" border="0">
    </a>

    <a href="https://orcid.org/0000-0002-7648-9979" target="_blank">
     <img
          src="img/orcid_id_1024px.svg.png"
          alt="View Somesh Singh's ORCID record" width="32" height="32" style="padding: 5px;" border="0">
    </a>
</span>


<!-- Removing the display of last updated date -->
<!--

  <div align="left">

  <p id="P1">
    <script language="Javascript">
    var dLM = new Date(Date.parse(document.lastModified));

       // var day = new Array("Sunday","Monday","Tuesday",
        //    "Wednesday","Thursday","Friday","Saturday");
        var month = new Array("January","February","March","April","May","June",
            "July","August","September","October","November","December");

        var date = dLM.getDate();
       // var day = day[dLM.getDay()];
        var year = dLM.getFullYear();
        var month = month[dLM.getMonth()];
        var hours = dLM.getHours();
        var minutes = dLM.getMinutes();
        var seconds = dLM.getSeconds();

        if (date<10) date = "0"+date;
        if (month<10) month = "0"+month;
        if (hours<10) hours = "0"+hours;
        if (minutes<10) minutes = "0"+minutes;
        if (seconds<10) seconds = "0"+seconds;

        document.write("Last updated: "
            + month+" "+date+", "+year+".");
        //document.write("Last Modified: "
        //    +day+", "+date+". "+month+" "+year+", um "+hours+":"+minutes+":"+seconds);
    </script>
  </p>
  </div>
  -->

  </div>

    </div>
    <!-- /.container -->

    <!-- jQuery Version 1.11.1 -->
    <script src="js/jquery.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="js/bootstrap.min.js"></script>

</body>

</html>




